{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eating Magical Cakes with Dynamic Programming\n",
    "\n",
    "> Finding the optimal saving rate with dynamic programming.\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: David Ngo\n",
    "- image: images/cake.jpeg\n",
    "- categories: [economics, mathematics, python]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](my_icons/fastai_logo.png)\n",
    "\n", 
    "In layman terms, [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) is a method of mathematical optimization—breaking down a complex problem into simpler parts and storing the results to save on computing power. We use dynamic programming to efficiently calculate the Bellman equation and determine optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Suppose a nice genie has given us a magic cake. The cake's initial size at time 0 is $y_0z_0$, some known number. Once per day, we are allowed to eat a piece of any size from the cake. Overnight, the cake will regenerate with multiplicative random variable $z_t$ whose logarithm is independently and identically distributed $N(\\mu, \\sigma)$. This means we potentially have an unlimited source of cake! \n",
    "\n",
    "Suppose the genie places the condition that we must choose a constant fraction of the cake to eat each day. As rational economists, we want to fully maximize our happiness by eating the right amount of cake each day. For this experiment, we can assume our utility function to be $E\\big[\\sum_{t=0}^{\\infty}\\beta^tu(c_t)\\big]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "We apply the following:\n",
    "\n",
    "1. Guess that the optimal policy is to eat a constant fraction of the magic cake in every period. \n",
    "2. Assume that $u(c) = \\frac{c^{1-r}-1}{1-r}$ for $r \\geq 0$. Fix $z_0y_0=69$, $r=2$, $\\beta = 0.95$, $\\mu=0$, and $\\sigma = 0.1$. \n",
    "4. Using np.random.seed(1234), generate a fixed sequence of 100 log normally distributed random variables. \n",
    "5. Use Python to search for the fraction that maximizes the expected reward for that fixed sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "We use the following terminology:\n",
    "\n",
    "- The **state** space, denoted $X$ is the size of the cake when we start with $(y_0, z_0)$.\n",
    "- The **control,** denoted $U$, is the piece of any size from the cake that you choose to eat. So we have $u \\in U$ such that $0 < u < 1$.\n",
    "- The **law of motion** represents the transition into the next price. This is the the multiplicative random variable or shock $z_t$, whose logarithm is independently and identically distributed $N(\\mu, \\sigma)$.\n",
    "- The **reward** $r$ is $r: X \\times Y \\rightarrow \\mathbb{R}$, so we have the reward r(x,y) for $x \\in X$ if we choose some fraction $u \\in U$.\n",
    "- The **discount factor** is $\\beta$, how much we discount to forgo current felicity in favor of future felicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dynamic Program\n",
    "\n",
    "Let us reiterate what we know so far:\n",
    "\n",
    "<ol>\n",
    "    <li> The state space is the random size of the cake</li>  \n",
    "    <li> The control space is how much one eats in period $t$</li> \n",
    "    <li> The law of motion is $x_{t+1} = z_{t+1}(x_t-c_t)$, where $x_t$ is the known size of the cake at time $t$. $z_{t+1}$ is lognormally distributed with parameters $\\mu$ and $\\sigma$.</li> \n",
    "    <li> The reward function is $u(c)$.</li>\n",
    "    <li> The discount factor is $\\beta$. </li>   \n",
    "</ol>\n",
    "\n",
    "For this problem, we can apply the Bellman equation:\n",
    "\n",
    "$$\n",
    "V(x_t) = max_{c_t \\in [0,x_t]}\\left\\{ u(c_t) + \\beta E[V\\left(z_{t+1}(x_t-c_t)\\right)|z_t] \\right\\}\n",
    "$$\n",
    "\n",
    "$V(\\cdot)$ represents a value fuction where, for each $c$ given a value $0 \\leq u \\leq 1$, we maximize the expected value of the optimal plan. Essentially, the bellman equation lets us find the optimal solution of a complex, iterative problems by breaking it down into simpler parts—which is why we use dynmaic programming to solve this problem. An explanation of the bellman equation can be found [here](https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first initialize the values of the state space: we assume that $u(c) = \\frac{c^{1-r}-1}{1-r}$ for $r \\geq 0$. Fix $z_0y_0=69$, $r=2$, $\\beta = 0.95$, $\\mu=0$, and $\\sigma = 0.1$. We then generate a fixed sequence of 100 log normally distributed random variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Finding the fraction that maximizes the expected reward for the fixed sequence\n",
    "\n",
    "z0y0 = 69\n",
    "r = 2\n",
    "beta = 0.97\n",
    "mu = 0\n",
    "sigma = .1\n",
    "T = 100\n",
    "\n",
    "# Generate a fixed sequence of 100 log normally distributed random variables.\n",
    "np.random.seed(1234)\n",
    "sequence = np.random.lognormal(mu, sigma, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the felicity (utility) function. We use this to calculate our happiness for given amount of cake we consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felicity function\n",
    "\n",
    "def felicity(c,r):\n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    Computing the felicity given consumption c\n",
    "    and reward r\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    # u(c)\n",
    "    u = (c**(1-r)-1) / (1-r)\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a function to calculate our utility overtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value function\n",
    "\n",
    "def bigU(c, beta, r, T):\n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    Computing the sum of utilities\n",
    "    C is the sequence of consumption\n",
    "    beta is the discount factor\n",
    "    r is the reward curvature\n",
    "    T is the time period\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    U = 0\n",
    "    for t in range(T):\n",
    "        utility = beta**(t)*felicity(c[t], r)\n",
    "        U+= utility\n",
    "    \n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function to calculate the law of motion. We need this to figure out how much the cake will grow in the next period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Law of motion\n",
    "\n",
    "def motion(initial_state, z, share):\n",
    "    \"\"\"\"\"\n",
    "    Computing the sequence of consumption\n",
    "    z equals a sequence of numbers, representing \n",
    "    the random shocks to the size of the cake \n",
    "    given the initial state\n",
    "   \n",
    "    \"\"\"\"\"\n",
    "\n",
    "    c = []\n",
    "    y_0 = initial_state\n",
    "    c_0 = share * y_0\n",
    "    c.append(c_0)\n",
    "    for t in range(len(z)):\n",
    "        y_1 = z[t] * (y_0 - c_0)\n",
    "        c_1 = share*y_1\n",
    "        c.append(c_1)\n",
    "        y_0 = y_1\n",
    "        c_0 = c_1\n",
    "        \n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the above functions to create a function that determines the fraction of the cake that yields the maximum utility overtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best constant fraction is 0.22 and the maximum utility is 25.71\n"
     ]
    }
   ],
   "source": [
    "# Maximize expected reward function\n",
    "\n",
    "# Initial values\n",
    "z0y0 = 69\n",
    "r = .2\n",
    "beta = 0.95\n",
    "mu = 0\n",
    "sigma = .1\n",
    "T = 100\n",
    "\n",
    "\n",
    "def max_cake(initial_state, \n",
    "             beta, \n",
    "             r, \n",
    "             mu,\n",
    "             sigma,\n",
    "             T, \n",
    "             a, \n",
    "             b, \n",
    "             increment):\n",
    "\n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    Finding the number in range [a,b] that provides \n",
    "    the maximum utility\n",
    "    initial_state is the size of the cake at state 0\n",
    "    beta is the discount factor\n",
    "    r is some given value to compute utility for this case\n",
    "    T is the period of time\n",
    "    mu is the given mean\n",
    "    sigma is the given standard deviation\n",
    "    initial_state is the size of the cake at state 0\n",
    "    Given the range a to b, with increments from a to b\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    \n",
    "    # Generate a fixed sequence of T log normally distributed random variables.\n",
    "    np.random.seed(1234)\n",
    "    sequence = np.random.lognormal(mu, sigma, T)\n",
    "    \n",
    "    # Array of fractions\n",
    "    control = np.arange(a, b, increment)\n",
    "    \n",
    "    # Empty array\n",
    "    control_utilities = []\n",
    "    \n",
    "    # Compute value function for each constant fraction\n",
    "    for i in range(len(control)):\n",
    "        c = motion(initial_state, sequence, control[i])\n",
    "        utility = bigU(c, beta, r, T)\n",
    "        control_utilities.append(utility)\n",
    "        \n",
    "    # Find the fraction that maximizes utility\n",
    "    print('The best constant fraction is', \n",
    "          control[control_utilities.index(max(control_utilities))], \n",
    "          'and the maximum utility is', round(max(control_utilities),2))\n",
    "\n",
    "max_cake(z0y0, beta, r, mu, sigma, T, .001, 1, .001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Provided that the optimal policy is to eat a constant fraction of the magic cake in every period, we find that eating 22% of the cake each day maximizes our expected reward for the fixed sequence. Thank you genie!\n",
    "\n",
    "Things to consider: We made assumptions on our reward function, discount factor, etc. If we were to change the value of these conditions, there is no doubnt that our best constant fraction and maximum utility would also change. And just because we are \"happiest\" does not mean we are happy at all! I imagine that once I choose a fraction of the cake to eat for each day, I would be compelled to eat the same flavored cake every day for the rest of my life. What a sneaky genie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "Photo by [Jacob Schwartz](https://unsplash.com/@rosenberg12?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash.](https://unsplash.com/s/photos/cake?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)\n",
    "  \n",
    "This exercise is based on Sargent and Stachurski's article on [Optimal Saving.](https://python.quantecon.org/cake_eating_problem.html) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
