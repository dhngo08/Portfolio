{
  
    
        "post0": {
            "title": "Eating Magical Cakes with Dynamic Programming",
            "content": ". In layman terms, dynamic programming is a method of mathematical optimization—breaking down a complex problem into simpler parts and storing the results to save on computing power. We use dynamic programming to efficiently calculate the Bellman equation and determine optimal solutions. . Background . Suppose a nice genie has given us a magic cake. The cake&#39;s initial size at time 0 is $y_0z_0$, some known number. Once per day, we are allowed to eat a piece of any size from the cake. Overnight, the cake will regenerate with multiplicative random variable $z_t$ whose logarithm is independently and identically distributed $N( mu, sigma)$. This means we potentially have an unlimited source of cake! . Suppose the genie places the condition that we must choose a constant fraction of the cake to eat each day. As rational economists, we want to fully maximize our happiness by eating the right amount of cake each day. For this experiment, we can assume our utility function to be $E big[ sum_{t=0}^{ infty} beta^tu(c_t) big]$. . Exercise . We apply the following: . Guess that the optimal policy is to eat a constant fraction of the magic cake in every period. | Assume that $u(c) = frac{c^{1-r}-1}{1-r}$ for $r geq 0$. Fix $z_0y_0=69$, $r=2$, $ beta = 0.95$, $ mu=0$, and $ sigma = 0.1$. | Using np.random.seed(1234), generate a fixed sequence of 100 log normally distributed random variables. | Use Python to search for the fraction that maximizes the expected reward for that fixed sequence. | Terminology . We use the following terminology: . The state space, denoted $X$ is the size of the cake when we start with $(y_0, z_0)$. | The control, denoted $U$, is the piece of any size from the cake that you choose to eat. So we have $u in U$ such that $0 &lt; u &lt; 1$. | The law of motion represents the transition into the next price. This is the the multiplicative random variable or shock $z_t$, whose logarithm is independently and identically distributed $N( mu, sigma)$. | The reward $r$ is $r: X times Y rightarrow mathbb{R}$, so we have the reward r(x,y) for $x in X$ if we choose some fraction $u in U$. | The discount factor is $ beta$, how much we discount to forgo current felicity in favor of future felicity. | . Setting up the Dynamic Program . Let us reiterate what we know so far: . The state space is the random size of the cake | The control space is how much one eats in period $t$ | The law of motion is $x_{t+1} = z_{t+1}(x_t-c_t)$, where $x_t$ is the known size of the cake at time $t$. $z_{t+1}$ is lognormally distributed with parameters $ mu$ and $ sigma$. | The reward function is $u(c)$. | The discount factor is $ beta$. | For this problem, we can apply the Bellman equation: . $$ V(x_t) = max_{c_t in [0,x_t]} left { u(c_t) + beta E[V left(z_{t+1}(x_t-c_t) right)|z_t] right } $$$V( cdot)$ represents a value fuction where, for each $c$ given a value $0 leq u leq 1$, we maximize the expected value of the optimal plan. Essentially, the bellman equation lets us find the optimal solution of a complex, iterative problems by breaking it down into simpler parts—which is why we use dynmaic programming to solve this problem. An explanation of the bellman equation can be found here. . Code . Let us first initialize the values of the state space: we assume that $u(c) = frac{c^{1-r}-1}{1-r}$ for $r geq 0$. Fix $z_0y_0=69$, $r=2$, $ beta = 0.95$, $ mu=0$, and $ sigma = 0.1$. We then generate a fixed sequence of 100 log normally distributed random variables. . import numpy as np # Finding the fraction that maximizes the expected reward for the fixed sequence z0y0 = 69 r = 2 beta = 0.97 mu = 0 sigma = .1 T = 100 # Generate a fixed sequence of 100 log normally distributed random variables. np.random.seed(1234) sequence = np.random.lognormal(mu, sigma, T) . Next, we create the felicity (utility) function. We use this to calculate our happiness for given amount of cake we consume. . def felicity(c,r): &quot;&quot;&quot;&quot;&quot; Computing the felicity given consumption c and reward r &quot;&quot;&quot;&quot;&quot; # u(c) u = (c**(1-r)-1) / (1-r) return u . We can then create a function to calculate our utility overtime. . def bigU(c, beta, r, T): &quot;&quot;&quot;&quot;&quot; Computing the sum of utilities C is the sequence of consumption beta is the discount factor r is the reward curvature T is the time period &quot;&quot;&quot;&quot;&quot; U = 0 for t in range(T): utility = beta**(t)*felicity(c[t], r) U+= utility return U . Now we create a function to calculate the law of motion. We need this to figure out how much the cake will grow in the next period. . def motion(initial_state, z, share): &quot;&quot;&quot;&quot;&quot; Computing the sequence of consumption z equals a sequence of numbers, representing the random shocks to the size of the cake given the initial state &quot;&quot;&quot;&quot;&quot; c = [] y_0 = initial_state c_0 = share * y_0 c.append(c_0) for t in range(len(z)): y_1 = z[t] * (y_0 - c_0) c_1 = share*y_1 c.append(c_1) y_0 = y_1 c_0 = c_1 return c . Finally, we can use the above functions to create a function that determines the fraction of the cake that yields the maximum utility overtime. . # Initial values z0y0 = 69 r = .2 beta = 0.95 mu = 0 sigma = .1 T = 100 def max_cake(initial_state, beta, r, mu, sigma, T, a, b, increment): &quot;&quot;&quot;&quot;&quot; Finding the number in range [a,b] that provides the maximum utility initial_state is the size of the cake at state 0 beta is the discount factor r is some given value to compute utility for this case T is the period of time mu is the given mean sigma is the given standard deviation initial_state is the size of the cake at state 0 Given the range a to b, with increments from a to b &quot;&quot;&quot;&quot;&quot; # Generate a fixed sequence of T log normally distributed random variables. np.random.seed(1234) sequence = np.random.lognormal(mu, sigma, T) # Array of fractions control = np.arange(a, b, increment) # Empty array control_utilities = [] # Compute value function for each constant fraction for i in range(len(control)): c = motion(initial_state, sequence, control[i]) utility = bigU(c, beta, r, T) control_utilities.append(utility) # Find the fraction that maximizes utility print(&#39;The best constant fraction is&#39;, control[control_utilities.index(max(control_utilities))], &#39;and the maximum utility is&#39;, round(max(control_utilities),2)) max_cake(z0y0, beta, r, mu, sigma, T, .001, 1, .001) . The best constant fraction is 0.22 and the maximum utility is 25.71 . Conclusion . Provided that the optimal policy is to eat a constant fraction of the magic cake in every period, we find that eating 22% of the cake each day maximizes our expected reward for the fixed sequence. Thank you genie! . Things to consider: We made assumptions on our reward function, discount factor, etc. If we were to change the value of these conditions, there is no doubnt that our best constant fraction and maximum utility would also change. And just because we are &quot;happiest&quot; does not mean we are happy at all! I imagine that once I choose a fraction of the cake to eat for each day, I would be compelled to eat the same flavored cake every day for the rest of my life. What a sneaky genie! . Credits . Photo by Jacob Schwartz on Unsplash. . This exercise is based on Sargent and Stachurski&#39;s article on Optimal Saving. .",
            "url": "https://dhngo08.github.io/Portfolio/economics/mathematics/python/2021/10/21/Magic-Cake.html",
            "relUrl": "/economics/mathematics/python/2021/10/21/Magic-Cake.html",
            "date": " • Oct 21, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Visualizing Real GDP and Unemployment Rate",
            "content": "I made a couple of simple charts, one to visualize the year-over-year Real Gross Domestic Product (GDP) growth in the United States and another for the rate of unemployment overtime. Data comes from the St. Louis Federal Reserve, Federal Reserve Economic Data. . By year-over-year, I am comparing the GDP of one quarter with the same quarter in the previous year. For example, the growth rate of Real GDP in the first quarter of 2020 would be: . $$ %Growth_{2020} = frac{GDP_{2020} - GDP_{2019}}{GDP_{2019}} times 100$$ .",
            "url": "https://dhngo08.github.io/Portfolio/data%20visualization/economics/python/2021/10/14/GDP-Unemployment-Rate-Charts.html",
            "relUrl": "/data%20visualization/economics/python/2021/10/14/GDP-Unemployment-Rate-Charts.html",
            "date": " • Oct 14, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Monte Carlo Numerical Integration",
            "content": "For this exercise, I apply Monte Carlo to randomly draw $(x, y)$ values in $[- pi, pi] times [0,1]$. . I then use those values to compute $ int^ pi_{- pi}|cos(2x)|dx=4$. . The code is as follows: . import math import numpy as np from scipy import random # string &#39;fx&#39; is a function in terms of x # a is the lower limit # b is the upper limit # n is the sample size def mc_integral(fx,a,b,n): # defining monte carlo numerical integration method func = lambda x: eval(fx) # argument x and function fx; string fx is parsed and evaluated as a python expression xrand = random.uniform(a,b,n) # generating x values from a normal distribution with range a to b sum_fx = 0 # empty arry to store y values of fx for i in range(n): sum_fx += func(xrand[i]) # summation of computing x values into fx to generate y values answer = (b-a)/n * sum_fx # computing the definite integral of fx between a and b return answer . The function mc_integral should produce some pretty accurate integrations. . Let us try integrating $|cos(2x)|$ with the lower bound $- pi$, upper bound $ pi$, and a sample size 100,000. . print(mc_integral(&#39;abs(math.cos(2*x))&#39;,-np.pi,np.pi, 100000)) . 4.00146350409084 . With the above code, we find that $ int^ pi_{- pi}|cos(2x)|dx approx4$, a value very close to 4. I suppose that&#39;s decent enough :+1: .",
            "url": "https://dhngo08.github.io/Portfolio/mathematics/python/2021/10/09/Monte-Carlo-Numerical-Integration.html",
            "relUrl": "/mathematics/python/2021/10/09/Monte-Carlo-Numerical-Integration.html",
            "date": " • Oct 9, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". I am a Research Analyst at Onpoint Analystics Inc., a company that provides economic and statistical consulting services for legal proceedings and business disputes. I perform market research, data analysis, programming and visualization, economic and statistical analysis, and document research. Really, I consider myself a data junkie. . I graduated with a B.A. in Combined Math/Economics at UC Santa Cruz and an M.S. in Quantitative Economics from Cal Poly San Luis Obispo. At Cal Poly, I worked with the Digital Transformation Hub and the World Bank to predict food insecurity in Latin American regions using machine learning algorithms. See more on that here. . In my free time, I enjoy practicing Python and SQL, learning the guitar, and playing tabletop games. .",
          "url": "https://dhngo08.github.io/Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dhngo08.github.io/Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}